{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab55bde-a467-42b9-aed0-7ba825740356",
   "metadata": {},
   "source": [
    "# OM SAI RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7838ccd2-c75f-4de0-9abe-5e70c34ef31a",
   "metadata": {},
   "source": [
    "# ML FRAMEWORK FOR AUTISM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3382e19f-03c2-4b6d-be91-8f3439b8b78d",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b27f58-adb7-4055-8ec2-b86df4a8f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Imports\n",
    "# --------------------------\n",
    "import os, math, re, warnings, zipfile, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Data & Math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
    ")\n",
    "\n",
    "# ML Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Audio\n",
    "import librosa\n",
    "\n",
    "# Suppress warnings for clean output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --------------------------\n",
    "# Directories\n",
    "# --------------------------\n",
    "OUTDIR = Path(\"outputs\")\n",
    "OUTDIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf4568-954a-40e5-9692-8124293f28a7",
   "metadata": {},
   "source": [
    "## Importing questionnare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357ad3e0-77be-4855-9ee6-b277c661d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfq = pd.read_csv(\"toddler_autism.csv\")  # change if filename differs\n",
    "dfq.columns = [c.strip().replace(\" \", \"_\") for c in dfq.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be664b83-8387-467c-94f3-29e33a7b359f",
   "metadata": {},
   "source": [
    "## questinnare preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58137ad-1930-4f4e-b911-cf945015aa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[questionnaire] rows=1000 label=Family_ASD_History features=7\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Questionnaire Preprocessing\n",
    "# --------------------------\n",
    "\n",
    "# Detect label column automatically\n",
    "label_candidates = [c for c in dfq.columns if \"class\" in c.lower() or \"asd\" in c.lower()]\n",
    "label_col = label_candidates[0] if label_candidates else \"Family_ASD_History\"\n",
    "\n",
    "# Function: convert Yes/No/etc. → binary\n",
    "def to_binary_series(s):\n",
    "    mapping = {\n",
    "        \"yes\": 1, \"no\": 0, \"true\": 1, \"false\": 0,\n",
    "        \"asd\": 1, \"no_asd\": 0, \"non-asd\": 0,\n",
    "        \"negative\": 0, \"positive\": 1\n",
    "    }\n",
    "    return s.astype(str).str.strip().str.lower().map(mapping)\n",
    "\n",
    "# Clean labels\n",
    "dfq[label_col] = to_binary_series(dfq[label_col]).fillna(0).astype(int)\n",
    "\n",
    "# Preprocess features\n",
    "q_feats = []\n",
    "for c in dfq.columns:\n",
    "    if c == label_col:\n",
    "        continue\n",
    "    if dfq[c].dtype == object:               # convert categorical to binary if possible\n",
    "        dfq[c] = to_binary_series(dfq[c])\n",
    "    dfq[c] = pd.to_numeric(dfq[c], errors=\"coerce\")  # force numeric\n",
    "    if dfq[c].notna().sum() > 0:\n",
    "        q_feats.append(c)\n",
    "\n",
    "# Final X, y\n",
    "Xq = dfq[q_feats].fillna(dfq[q_feats].median())  # impute missing with median\n",
    "y  = dfq[label_col].values\n",
    "\n",
    "print(f\"[questionnaire] rows={len(dfq)} label={label_col} features={len(q_feats)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6e9602-3fc2-4917-8d84-f3273affe084",
   "metadata": {},
   "source": [
    "## importing audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "996a71fb-5b8e-47fc-8b80-0c3b69232583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[audio] processed 100/500\n",
      "[audio] processed 200/500\n",
      "[audio] processed 300/500\n",
      "[audio] processed 400/500\n",
      "[audio] processed 500/500\n",
      "[speech] rows=500, features=55\n"
     ]
    }
   ],
   "source": [
    "# === SPEECH IMPORTING (FEATURE EXTRACTION) ===\n",
    "\n",
    "def extract_audio_features(path, sr_target=16000, n_mfcc=13):\n",
    "    try:\n",
    "        # Load audio\n",
    "        y, sr = librosa.load(path, sr=sr_target, mono=True)\n",
    "        if y.size == 0:\n",
    "            return None\n",
    "\n",
    "        # Trim silence\n",
    "        y, _ = librosa.effects.trim(y, top_db=30)\n",
    "\n",
    "        # MFCC features\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfcc_mean = mfcc.mean(axis=1)\n",
    "        mfcc_std  = mfcc.std(axis=1)\n",
    "\n",
    "        # Deltas\n",
    "        d1 = librosa.feature.delta(mfcc)\n",
    "        d2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "        # Spectral features\n",
    "        centroid  = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
    "        rolloff   = librosa.feature.spectral_rolloff(y=y, sr=sr).mean()\n",
    "        bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr).mean()\n",
    "\n",
    "        # Collect into dictionary\n",
    "        feat = {}\n",
    "        feat.update({f\"mfcc_mean_{i}\": v for i, v in enumerate(mfcc_mean)})\n",
    "        feat.update({f\"mfcc_std_{i}\":  v for i, v in enumerate(mfcc_std)})\n",
    "        feat.update({f\"delta1_{i}\":    v for i, v in enumerate(d1.mean(axis=1))})\n",
    "        feat.update({f\"delta2_{i}\":    v for i, v in enumerate(d2.mean(axis=1))})\n",
    "        feat[\"centroid\"]   = centroid\n",
    "        feat[\"rolloff\"]    = rolloff\n",
    "        feat[\"bandwidth\"]  = bandwidth\n",
    "        feat[\"audio_file\"] = str(path)\n",
    "        return feat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[error] {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def build_speech_features_df(audio_root, max_files=500, exts=(\".wav\", \".flac\", \".mp3\")):\n",
    "    files = [f for f in Path(audio_root).rglob(\"*\") if f.suffix.lower() in exts][:max_files]\n",
    "    rows = []\n",
    "    for i, f in enumerate(files, 1):\n",
    "        feat = extract_audio_features(f)\n",
    "        if feat:\n",
    "            rows.append(feat)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"[audio] processed {i}/{len(files)}\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.dropna(axis=1, how=\"all\").reset_index(drop=True)  # remove empty cols\n",
    "    return df\n",
    "\n",
    "\n",
    "# Build dataset\n",
    "dfs = build_speech_features_df(\"data/speech\", max_files=500)\n",
    "print(f\"[speech] rows={len(dfs)}, features={dfs.shape[1]-1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755911ad-ffd8-4a69-8e65-cac426ce4850",
   "metadata": {},
   "source": [
    "## Speech Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "654eba00-c567-49d9-abea-a41e035fe679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[speech preprocessing] Demo skipped (no sample file found).\n"
     ]
    }
   ],
   "source": [
    "# === SPEECH PREPROCESSING ===\n",
    "\n",
    "# Example function for speech preprocessing\n",
    "def preprocess_audio(file_path, sr=16000):\n",
    "    # Load audio\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "\n",
    "    # 1. Noise reduction (simple method: spectral gating or median filter)\n",
    "    y = librosa.effects.preemphasis(y)\n",
    "\n",
    "    # 2. Silence removal (trim leading/trailing silence)\n",
    "    y, _ = librosa.effects.trim(y, top_db=20)\n",
    "\n",
    "    return y, sr\n",
    "\n",
    "# Example demo on one file (optional check)\n",
    "example_file = \"data/speech/sample.wav\"  # <-- replace with actual file\n",
    "if os.path.exists(example_file):\n",
    "    y, sr = preprocess_audio(example_file)\n",
    "    print(f\"[speech preprocessing] Processed {len(y)} samples at {sr} Hz\")\n",
    "else:\n",
    "    print(\"[speech preprocessing] Demo skipped (no sample file found).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065bf19a-406b-4eb4-9216-87fc0b2456e8",
   "metadata": {},
   "source": [
    "## aliging speech with questionarre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59f97a90-d861-47d3-abe8-0a31fe4e398d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[align] Questionnaire rows=1000, Speech rows=500, Hybrid shape=(1000, 62)\n"
     ]
    }
   ],
   "source": [
    "# === ALIGNING SPEECH WITH QUESTIONNAIRE ===\n",
    "\n",
    "if not dfs.empty:\n",
    "    reps = math.ceil(len(dfq) / len(dfs))  # repeat speech features\n",
    "    dfs_rep = pd.concat([dfs.drop(columns=[\"audio_file\"])] * reps,\n",
    "                        ignore_index=True).iloc[:len(dfq)]\n",
    "    Xs = dfs_rep.reset_index(drop=True)\n",
    "    Xh = pd.concat([dfq[q_feats].reset_index(drop=True), Xs], axis=1)\n",
    "\n",
    "    print(f\"[align] Questionnaire rows={len(dfq)}, Speech rows={len(dfs)}, Hybrid shape={Xh.shape}\")\n",
    "else:\n",
    "    print(\"[align] No speech features available → Skipping Speech & Hybrid.\")\n",
    "    Xs = pd.DataFrame(index=dfq.index)  # empty placeholder\n",
    "    Xh = dfq[q_feats].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351fa4ea-d8dc-40ec-888c-2ba895916f53",
   "metadata": {},
   "source": [
    "## Imputation +SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a209e39b-a326-4708-9d85-cde92ba43eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SMOTE] Questionnaire (1300, 7) | Speech (1300, 55) | Hybrid (1300, 62)\n",
      "[SMOTE] Class distribution: [650 650]\n"
     ]
    }
   ],
   "source": [
    "# === BLOCK 2: IMPUTATION + SMOTE ===\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Handle missing values\n",
    "Xq_imp = imputer.fit_transform(dfq[q_feats])   # Questionnaire\n",
    "Xs_imp = imputer.fit_transform(Xs)             # Speech\n",
    "Xh_imp = imputer.fit_transform(Xh)             # Hybrid\n",
    "\n",
    "# Balance using SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "Xq_bal, y_bal = sm.fit_resample(Xq_imp, y)\n",
    "Xs_bal, y_bal = sm.fit_resample(Xs_imp, y)\n",
    "Xh_bal, y_bal = sm.fit_resample(Xh_imp, y)\n",
    "\n",
    "print(f\"[SMOTE] Questionnaire {Xq_bal.shape} | Speech {Xs_bal.shape} | Hybrid {Xh_bal.shape}\")\n",
    "print(f\"[SMOTE] Class distribution: {np.bincount(y_bal)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73494b-2016-4411-9fbd-e4b7ceac9817",
   "metadata": {},
   "source": [
    "## spilitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f803d1e-dc72-4542-88cc-8d78a47bfdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Split] Questionnaire train=(1040, 7), test=(260, 7)\n",
      "[Split] Speech train=(1040, 55), test=(260, 55)\n",
      "[Split] Hybrid train=(1040, 62), test=(260, 62)\n"
     ]
    }
   ],
   "source": [
    "# === BLOCK 1: TRAIN-TEST SPLIT ===\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xq_train, Xq_test, y_train, y_test = train_test_split(\n",
    "    Xq_bal, y_bal, test_size=0.2, random_state=42, stratify=y_bal\n",
    ")\n",
    "Xs_train, Xs_test, _, _ = train_test_split(\n",
    "    Xs_bal, y_bal, test_size=0.2, random_state=42, stratify=y_bal\n",
    ")\n",
    "Xh_train, Xh_test, _, _ = train_test_split(\n",
    "    Xh_bal, y_bal, test_size=0.2, random_state=42, stratify=y_bal\n",
    ")\n",
    "\n",
    "print(f\"[Split] Questionnaire train={Xq_train.shape}, test={Xq_test.shape}\")\n",
    "print(f\"[Split] Speech train={Xs_train.shape}, test={Xs_test.shape}\")\n",
    "print(f\"[Split] Hybrid train={Xh_train.shape}, test={Xh_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57347a88-fe49-4334-ab2a-3ae8af356389",
   "metadata": {},
   "source": [
    "## Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85303762-fe45-4933-ae99-55b112780550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scaler] Standardization applied to all feature sets\n"
     ]
    }
   ],
   "source": [
    "# === BLOCK 3: STANDARDIZATION ===\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "Xq_train = scaler.fit_transform(Xq_train)\n",
    "Xq_test  = scaler.transform(Xq_test)\n",
    "\n",
    "Xs_train = scaler.fit_transform(Xs_train)\n",
    "Xs_test  = scaler.transform(Xs_test)\n",
    "\n",
    "Xh_train = scaler.fit_transform(Xh_train)\n",
    "Xh_test  = scaler.transform(Xh_test)\n",
    "\n",
    "print(\"[Scaler] Standardization applied to all feature sets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb1003-4028-4e65-b297-bab80ac6af4a",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f18cc78-2cfd-479f-8e6c-951d4b1c8c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Models] 5 models initialized\n"
     ]
    }
   ],
   "source": [
    "# === BLOCK 4: DEFINE MODELS ===\n",
    "models = [\n",
    "    (\"LogReg\",   lambda: LogisticRegression(max_iter=700, class_weight=\"balanced\")),\n",
    "    (\"SVM\",      lambda: SVC(kernel=\"rbf\", probability=True, class_weight=\"balanced\")),\n",
    "    (\"RF\",       lambda: RandomForestClassifier(n_estimators=700, class_weight=\"balanced\", random_state=42)),\n",
    "    (\"XGB\",      lambda: XGBClassifier(n_estimators=700, eval_metric=\"logloss\", random_state=42)),\n",
    "    (\"CatBoost\", lambda: CatBoostClassifier(\n",
    "        iterations=700, learning_rate=0.05, depth=6,\n",
    "        auto_class_weights=\"Balanced\", verbose=0, random_state=42\n",
    "    ))\n",
    "]\n",
    "\n",
    "print(f\"[Models] {len(models)} models initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f4749-0ae6-42fd-80cc-c6e2798aadbf",
   "metadata": {},
   "source": [
    "## Train and Eval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "027e7bef-d590-4b55-a9cd-b56745e6030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BLOCK 5: TRAIN & EVALUATE FUNCTION ===\n",
    "def train_and_eval(X_train, y_train, X_test, y_test, model, name, prefix):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    # Metrics\n",
    "    acc  = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc  = roc_auc_score(y_test, y_proba) if y_proba is not None else np.nan\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"feature_set\": prefix,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25df624-fb9d-462c-869e-efa3a1c4ef58",
   "metadata": {},
   "source": [
    "## Training Loop and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb00049a-cbbc-48ac-b02c-0064bc9ba3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       model    feature_set  accuracy  precision    recall        f1   roc_auc\n",
      "5        SVM         Hybrid  0.703846   0.712000  0.684615  0.698039  0.742544\n",
      "14  CatBoost         Hybrid  0.700000   0.728070  0.638462  0.680328  0.783254\n",
      "11       XGB         Hybrid  0.684615   0.693548  0.661538  0.677165  0.771006\n",
      "6         RF  Questionnaire  0.680769   0.732673  0.569231  0.640693  0.722219\n",
      "8         RF         Hybrid  0.669231   0.686441  0.623077  0.653226  0.744822\n",
      "12  CatBoost  Questionnaire  0.657692   0.681416  0.592308  0.633745  0.732663\n",
      "4        SVM         Speech  0.653846   0.658730  0.638462  0.648438  0.700740\n",
      "9        XGB  Questionnaire  0.650000   0.661157  0.615385  0.637450  0.718166\n",
      "3        SVM  Questionnaire  0.619231   0.639640  0.546154  0.589212  0.684142\n",
      "7         RF         Speech  0.607692   0.616667  0.569231  0.592000  0.619852\n",
      "13  CatBoost         Speech  0.603846   0.606299  0.592308  0.599222  0.619852\n",
      "2     LogReg         Hybrid  0.596154   0.601626  0.569231  0.584980  0.617929\n",
      "10       XGB         Speech  0.584615   0.588710  0.561538  0.574803  0.615000\n",
      "1     LogReg         Speech  0.580769   0.586777  0.546154  0.565737  0.600030\n",
      "0     LogReg  Questionnaire  0.542308   0.544000  0.523077  0.533333  0.582071\n"
     ]
    }
   ],
   "source": [
    "# === BLOCK 6: TRAINING LOOP & RESULTS ===\n",
    "results = []\n",
    "\n",
    "for name, mdl_fn in models:\n",
    "    for prefix, (Xtr, Xte) in [\n",
    "        (\"Questionnaire\", (Xq_train, Xq_test)),\n",
    "        (\"Speech\", (Xs_train, Xs_test)),\n",
    "        (\"Hybrid\", (Xh_train, Xh_test))\n",
    "    ]:\n",
    "        mdl = mdl_fn()\n",
    "        results.append(train_and_eval(Xtr, y_train, Xte, y_test, mdl, name, prefix))\n",
    "\n",
    "met = pd.DataFrame(results).sort_values(by=\"accuracy\", ascending=False)\n",
    "print(met)\n",
    "\n",
    "# Save results\n",
    "met.to_csv(\"outputs/model_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d12416d-ad23-4650-82d8-c751013d7c95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
